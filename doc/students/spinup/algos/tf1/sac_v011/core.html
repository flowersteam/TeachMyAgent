<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>TeachMyAgent.students.spinup.algos.tf1.sac_v011.core API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="../images/favicon-96x96.png" />
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>TeachMyAgent.students.spinup.algos.tf1.sac_v011.core</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import tensorflow as tf
from TeachMyAgent.students.spinup.utils import models

EPS = 1e-8

def placeholder(dim=None):
    return tf.placeholder(dtype=tf.float32, shape=(None,dim) if dim else (None,))

def placeholders(*args):
    return [placeholder(dim) for dim in args]

def mlp(x, hidden_sizes=(32,), activation=tf.tanh, output_activation=None):
    for h in hidden_sizes[:-1]:
        x = tf.layers.dense(x, units=h, activation=activation)
    return tf.layers.dense(x, units=hidden_sizes[-1], activation=output_activation)

def lstm(X, hidden_sizes=128, nenv=1, layer_norm=False):
    nbatch = X.shape[0]
    nsteps = nbatch // nenv

    h = tf.layers.flatten(X)

    M = tf.placeholder(tf.float32, [nbatch]) #mask (done t-1)
    S = tf.placeholder(tf.float32, [nenv, 2*hidden_sizes]) #states

    xs = models.batch_to_seq(h, nenv, nsteps)
    ms = models.batch_to_seq(M, nenv, nsteps)

    if layer_norm:
        h5, snew = models.lnlstm(xs, ms, S, scope=&#39;lnlstm&#39;, nh=hidden_sizes)
    else:
        h5, snew = models.lstm(xs, ms, S, scope=&#39;lstm&#39;, nh=hidden_sizes)

    h = models.seq_to_batch(h5)
    initial_state = np.zeros(S.shape.as_list(), dtype=float)

    return h, {&#39;S&#39;:S, &#39;M&#39;:M, &#39;state&#39;:snew, &#39;initial_state&#39;:initial_state}

def get_vars(scope):
    return [x for x in tf.global_variables() if scope in x.name]

def count_vars(scope):
    v = get_vars(scope)
    return sum([np.prod(var.shape.as_list()) for var in v])

def gaussian_likelihood(x, mu, log_std):
    pre_sum = -0.5 * (((x-mu)/(tf.exp(log_std)+EPS))**2 + 2*log_std + np.log(2*np.pi))
    return tf.reduce_sum(pre_sum, axis=1)

def clip_but_pass_gradient(x, l=-1., u=1.):
    clip_up = tf.cast(x &gt; u, tf.float32)
    clip_low = tf.cast(x &lt; l, tf.float32)
    return x + tf.stop_gradient((u - x)*clip_up + (l - x)*clip_low)


&#34;&#34;&#34;
Policies
&#34;&#34;&#34;

LOG_STD_MAX = 2
LOG_STD_MIN = -20

def mlp_gaussian_policy(x, a, hidden_sizes, activation, output_activation):
    act_dim = a.shape.as_list()[-1]
    net = mlp(x, list(hidden_sizes), activation, activation)
    mu = tf.layers.dense(net, act_dim, activation=output_activation)

    &#34;&#34;&#34;
    Because algorithm maximizes trade-off of reward and entropy,
    entropy must be unique to state---and therefore log_stds need
    to be a neural network output instead of a shared-across-states
    learnable parameter vector. But for deep Relu and other nets,
    simply sticking an activationless dense layer at the end would
    be quite bad---at the beginning of training, a randomly initialized
    net could produce extremely large values for the log_stds, which
    would result in some actions being either entirely deterministic
    or too random to come back to earth. Either of these introduces
    numerical instability which could break the algorithm. To 
    protect against that, we&#39;ll constrain the output range of the 
    log_stds, to lie within [LOG_STD_MIN, LOG_STD_MAX]. This is 
    slightly different from the trick used by the original authors of
    SAC---they used tf.clip_by_value instead of squashing and rescaling.
    I prefer this approach because it allows gradient propagation
    through log_std where clipping wouldn&#39;t, but I don&#39;t know if
    it makes much of a difference.
    &#34;&#34;&#34;
    log_std = tf.layers.dense(net, act_dim, activation=tf.tanh)
    log_std = LOG_STD_MIN + 0.5 * (LOG_STD_MAX - LOG_STD_MIN) * (log_std + 1)

    std = tf.exp(log_std)
    pi = mu + tf.random_normal(tf.shape(mu)) * std
    logp_pi = gaussian_likelihood(pi, mu, log_std)
    return mu, pi, logp_pi

def apply_squashing_func(mu, pi, logp_pi):
    mu = tf.tanh(mu)
    pi = tf.tanh(pi)
    # To avoid evil machine precision error, strictly clip 1-pi**2 to [0,1] range.
    logp_pi -= tf.reduce_sum(tf.log(clip_but_pass_gradient(1 - pi**2, l=0, u=1) + 1e-6), axis=1)
    return mu, pi, logp_pi


&#34;&#34;&#34;
Actor-Critics
&#34;&#34;&#34;
def mlp_actor_critic(x, a, hidden_sizes=(400,300), activation=tf.nn.relu, 
                     output_activation=None, policy=mlp_gaussian_policy, action_space=None):
    # policy
    with tf.variable_scope(&#39;pi&#39;):
        mu, pi, logp_pi = policy(x, a, hidden_sizes, activation, output_activation)
        mu, pi, logp_pi = apply_squashing_func(mu, pi, logp_pi)

    # make sure actions are in correct range
    action_scale = action_space.high[0]
    mu *= action_scale
    pi *= action_scale

    # vfs
    vf_mlp = lambda x : tf.squeeze(mlp(x, list(hidden_sizes)+[1], activation, None), axis=1)
    with tf.variable_scope(&#39;q1&#39;):
        q1 = vf_mlp(tf.concat([x,a], axis=-1))
    with tf.variable_scope(&#39;q1&#39;, reuse=True):
        q1_pi = vf_mlp(tf.concat([x,pi], axis=-1))
    with tf.variable_scope(&#39;q2&#39;):
        q2 = vf_mlp(tf.concat([x,a], axis=-1))
    with tf.variable_scope(&#39;q2&#39;, reuse=True):
        q2_pi = vf_mlp(tf.concat([x,pi], axis=-1))
    with tf.variable_scope(&#39;v&#39;):
        v = vf_mlp(x)
    return mu, pi, logp_pi, q1, q2, q1_pi, q2_pi, v</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.apply_squashing_func"><code class="name flex">
<span>def <span class="ident">apply_squashing_func</span></span>(<span>mu, pi, logp_pi)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_squashing_func(mu, pi, logp_pi):
    mu = tf.tanh(mu)
    pi = tf.tanh(pi)
    # To avoid evil machine precision error, strictly clip 1-pi**2 to [0,1] range.
    logp_pi -= tf.reduce_sum(tf.log(clip_but_pass_gradient(1 - pi**2, l=0, u=1) + 1e-6), axis=1)
    return mu, pi, logp_pi</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.clip_but_pass_gradient"><code class="name flex">
<span>def <span class="ident">clip_but_pass_gradient</span></span>(<span>x, l=-1.0, u=1.0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clip_but_pass_gradient(x, l=-1., u=1.):
    clip_up = tf.cast(x &gt; u, tf.float32)
    clip_low = tf.cast(x &lt; l, tf.float32)
    return x + tf.stop_gradient((u - x)*clip_up + (l - x)*clip_low)</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.count_vars"><code class="name flex">
<span>def <span class="ident">count_vars</span></span>(<span>scope)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count_vars(scope):
    v = get_vars(scope)
    return sum([np.prod(var.shape.as_list()) for var in v])</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.gaussian_likelihood"><code class="name flex">
<span>def <span class="ident">gaussian_likelihood</span></span>(<span>x, mu, log_std)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gaussian_likelihood(x, mu, log_std):
    pre_sum = -0.5 * (((x-mu)/(tf.exp(log_std)+EPS))**2 + 2*log_std + np.log(2*np.pi))
    return tf.reduce_sum(pre_sum, axis=1)</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.get_vars"><code class="name flex">
<span>def <span class="ident">get_vars</span></span>(<span>scope)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_vars(scope):
    return [x for x in tf.global_variables() if scope in x.name]</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.lstm"><code class="name flex">
<span>def <span class="ident">lstm</span></span>(<span>X, hidden_sizes=128, nenv=1, layer_norm=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lstm(X, hidden_sizes=128, nenv=1, layer_norm=False):
    nbatch = X.shape[0]
    nsteps = nbatch // nenv

    h = tf.layers.flatten(X)

    M = tf.placeholder(tf.float32, [nbatch]) #mask (done t-1)
    S = tf.placeholder(tf.float32, [nenv, 2*hidden_sizes]) #states

    xs = models.batch_to_seq(h, nenv, nsteps)
    ms = models.batch_to_seq(M, nenv, nsteps)

    if layer_norm:
        h5, snew = models.lnlstm(xs, ms, S, scope=&#39;lnlstm&#39;, nh=hidden_sizes)
    else:
        h5, snew = models.lstm(xs, ms, S, scope=&#39;lstm&#39;, nh=hidden_sizes)

    h = models.seq_to_batch(h5)
    initial_state = np.zeros(S.shape.as_list(), dtype=float)

    return h, {&#39;S&#39;:S, &#39;M&#39;:M, &#39;state&#39;:snew, &#39;initial_state&#39;:initial_state}</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.mlp"><code class="name flex">
<span>def <span class="ident">mlp</span></span>(<span>x, hidden_sizes=(32,), activation=&lt;function tanh&gt;, output_activation=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mlp(x, hidden_sizes=(32,), activation=tf.tanh, output_activation=None):
    for h in hidden_sizes[:-1]:
        x = tf.layers.dense(x, units=h, activation=activation)
    return tf.layers.dense(x, units=hidden_sizes[-1], activation=output_activation)</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.mlp_actor_critic"><code class="name flex">
<span>def <span class="ident">mlp_actor_critic</span></span>(<span>x, a, hidden_sizes=(400, 300), activation=&lt;function relu&gt;, output_activation=None, policy=&lt;function mlp_gaussian_policy&gt;, action_space=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mlp_actor_critic(x, a, hidden_sizes=(400,300), activation=tf.nn.relu, 
                     output_activation=None, policy=mlp_gaussian_policy, action_space=None):
    # policy
    with tf.variable_scope(&#39;pi&#39;):
        mu, pi, logp_pi = policy(x, a, hidden_sizes, activation, output_activation)
        mu, pi, logp_pi = apply_squashing_func(mu, pi, logp_pi)

    # make sure actions are in correct range
    action_scale = action_space.high[0]
    mu *= action_scale
    pi *= action_scale

    # vfs
    vf_mlp = lambda x : tf.squeeze(mlp(x, list(hidden_sizes)+[1], activation, None), axis=1)
    with tf.variable_scope(&#39;q1&#39;):
        q1 = vf_mlp(tf.concat([x,a], axis=-1))
    with tf.variable_scope(&#39;q1&#39;, reuse=True):
        q1_pi = vf_mlp(tf.concat([x,pi], axis=-1))
    with tf.variable_scope(&#39;q2&#39;):
        q2 = vf_mlp(tf.concat([x,a], axis=-1))
    with tf.variable_scope(&#39;q2&#39;, reuse=True):
        q2_pi = vf_mlp(tf.concat([x,pi], axis=-1))
    with tf.variable_scope(&#39;v&#39;):
        v = vf_mlp(x)
    return mu, pi, logp_pi, q1, q2, q1_pi, q2_pi, v</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.mlp_gaussian_policy"><code class="name flex">
<span>def <span class="ident">mlp_gaussian_policy</span></span>(<span>x, a, hidden_sizes, activation, output_activation)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mlp_gaussian_policy(x, a, hidden_sizes, activation, output_activation):
    act_dim = a.shape.as_list()[-1]
    net = mlp(x, list(hidden_sizes), activation, activation)
    mu = tf.layers.dense(net, act_dim, activation=output_activation)

    &#34;&#34;&#34;
    Because algorithm maximizes trade-off of reward and entropy,
    entropy must be unique to state---and therefore log_stds need
    to be a neural network output instead of a shared-across-states
    learnable parameter vector. But for deep Relu and other nets,
    simply sticking an activationless dense layer at the end would
    be quite bad---at the beginning of training, a randomly initialized
    net could produce extremely large values for the log_stds, which
    would result in some actions being either entirely deterministic
    or too random to come back to earth. Either of these introduces
    numerical instability which could break the algorithm. To 
    protect against that, we&#39;ll constrain the output range of the 
    log_stds, to lie within [LOG_STD_MIN, LOG_STD_MAX]. This is 
    slightly different from the trick used by the original authors of
    SAC---they used tf.clip_by_value instead of squashing and rescaling.
    I prefer this approach because it allows gradient propagation
    through log_std where clipping wouldn&#39;t, but I don&#39;t know if
    it makes much of a difference.
    &#34;&#34;&#34;
    log_std = tf.layers.dense(net, act_dim, activation=tf.tanh)
    log_std = LOG_STD_MIN + 0.5 * (LOG_STD_MAX - LOG_STD_MIN) * (log_std + 1)

    std = tf.exp(log_std)
    pi = mu + tf.random_normal(tf.shape(mu)) * std
    logp_pi = gaussian_likelihood(pi, mu, log_std)
    return mu, pi, logp_pi</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.placeholder"><code class="name flex">
<span>def <span class="ident">placeholder</span></span>(<span>dim=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def placeholder(dim=None):
    return tf.placeholder(dtype=tf.float32, shape=(None,dim) if dim else (None,))</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.placeholders"><code class="name flex">
<span>def <span class="ident">placeholders</span></span>(<span>*args)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def placeholders(*args):
    return [placeholder(dim) for dim in args]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<a href="http://developmentalsystems.org/TeachMyAgent/doc/">
<img src="../images/home/head_image.png" style="display: block; margin: 1em auto">
</a>
<a href="http://developmentalsystems.org/TeachMyAgent/doc/">Home</a> | <a href="http://developmentalsystems.org/TeachMyAgent/">Website</a>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="TeachMyAgent.students.spinup.algos.tf1.sac_v011" href="index.html">TeachMyAgent.students.spinup.algos.tf1.sac_v011</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.apply_squashing_func" href="#TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.apply_squashing_func">apply_squashing_func</a></code></li>
<li><code><a title="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.clip_but_pass_gradient" href="#TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.clip_but_pass_gradient">clip_but_pass_gradient</a></code></li>
<li><code><a title="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.count_vars" href="#TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.count_vars">count_vars</a></code></li>
<li><code><a title="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.gaussian_likelihood" href="#TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.gaussian_likelihood">gaussian_likelihood</a></code></li>
<li><code><a title="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.get_vars" href="#TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.get_vars">get_vars</a></code></li>
<li><code><a title="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.lstm" href="#TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.lstm">lstm</a></code></li>
<li><code><a title="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.mlp" href="#TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.mlp">mlp</a></code></li>
<li><code><a title="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.mlp_actor_critic" href="#TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.mlp_actor_critic">mlp_actor_critic</a></code></li>
<li><code><a title="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.mlp_gaussian_policy" href="#TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.mlp_gaussian_policy">mlp_gaussian_policy</a></code></li>
<li><code><a title="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.placeholder" href="#TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.placeholder">placeholder</a></code></li>
<li><code><a title="TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.placeholders" href="#TeachMyAgent.students.spinup.algos.tf1.sac_v011.core.placeholders">placeholders</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>